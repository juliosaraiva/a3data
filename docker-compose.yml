version: "3.9"

services:
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: incident-extractor-api
    environment:
      # Core app settings (override as needed)
      - LLM_PROVIDER=${LLM_PROVIDER:-ollama}
      - LLM_MODEL_NAME=${LLM_MODEL_NAME:-gemma3:4b}
      - LLM_BASE_URL=${LLM_BASE_URL:-http://ollama:11434}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - DEBUG=${DEBUG:-false}
      - PORT=8000
    ports:
      - "8000:8000"
    depends_on:
      - ollama
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:8000/health"]
      interval: 30s
      timeout: 5s
      retries: 3
    restart: unless-stopped

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    volumes:
      - ollama_models:/root/.ollama
    ports:
      - "11434:11434"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/version"]
      interval: 30s
      timeout: 5s
      retries: 5
    restart: unless-stopped

volumes:
  ollama_models:
