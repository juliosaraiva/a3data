.PHONY: help setup dev install run run-prod test format lint lint-fix type-check quality clean reset health check-deps check-env check-llm ollama-install ollama-start ollama-pull ollama-setup switch-to-openai switch-to-ollama logs api-check validate demo quick-start
.DEFAULT_GOAL := help

PROJECT_NAME := incident-extractor
PORT ?= 8000
HOST ?= 0.0.0.0
PYTHON ?= python3
OLLAMA_DEFAULT_MODEL := gemma3:4b

# Internal helpers
ENV_FILE := .env

help: ## ðŸ“– Show available commands (this help)
	@echo ""
	@echo "âœ¨ $(PROJECT_NAME) - Make Commands"
	@echo "--------------------------------"
	@grep -E '^[a-zA-Z0-9_.-]+:.*?## ' $(MAKEFILE_LIST) | awk -F':.*## ' '{printf "  \033[36m%-18s\033[0m %s\n", $$1, $$2}'
	@echo ""
	@echo "Shortcuts: \033[33ms\033[0m=setup \033[33mf\033[0m=format \033[33ml\033[0m=lint-fix \033[33mq\033[0m=quality \033[33mt\033[0m=test \033[33mh\033[0m=health \033[33mv\033[0m=validate"

setup: ## ðŸš€ One-command project setup (env + deps + ollama + health)
	@[ -f $(ENV_FILE) ] || cp .env.example $(ENV_FILE)
	@echo "[1/4] Syncing development dependencies"; uv sync --dev >/dev/null
	@echo "[2/4] Ensuring LLM provider readiness"; $(MAKE) ollama-setup >/dev/null || true
	@echo "[3/4] Running health checks"; $(MAKE) health
	@echo "[4/4] Done. Run 'make run' to start the server."

quick-start: ## ðŸƒ Setup and start server immediately
	$(MAKE) setup
	$(MAKE) run

demo: ## ðŸŽ­ Run interactive demo (setup + server + API validation)
	@echo "ðŸŽ­ Starting interactive demo..."
	@if pgrep -f "uvicorn.*main:app" > /dev/null; then \
		echo "Server already running, validating API..."; \
		$(MAKE) validate; \
	else \
		echo "Starting server in background..."; \
		$(MAKE) run &; \
		SERVER_PID=$$!; \
		echo "Waiting for server to start..."; \
		sleep 5; \
		echo "Validating API..."; \
		$(MAKE) validate || true; \
		echo "Demo complete. Server running with PID: $$SERVER_PID"; \
	fi

install: ## ðŸ“¦ Install production dependencies only
	uv sync --no-dev

dev: ## ðŸ› ï¸ Install / update development dependencies
	uv sync --dev

run: ## ðŸƒ Start FastAPI dev server (reload)
	PYTHONPATH=src uv run uvicorn main:app --reload --host $(HOST) --port $(PORT)

run-prod: ## ðŸ­ Start FastAPI production server
	PYTHONPATH=src uv run uvicorn main:app --host $(HOST) --port $(PORT)

test: ## ðŸ§ª Run tests
	uv run pytest

format: ## ðŸŽ¨ Format code
	uv run ruff format .

lint: ## ðŸ” Lint (no fix)
	uv run ruff check .

lint-fix: ## ðŸ§¹ Lint and auto-fix
	uv run ruff check . --fix

type-check: ## ðŸ”¬ Run pyright type checker
	uv run pyright .

quality: ## âœ… Format + lint-fix + type-check + tests
	$(MAKE) format
	$(MAKE) lint-fix
	$(MAKE) type-check
	$(MAKE) test

clean: ## ðŸ—‘ï¸ Remove caches and build artifacts
	find . -type f -name "*.pyc" -delete 2>/dev/null || true
	find . -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true
	rm -rf .pytest_cache .pyright_cache .ruff_cache htmlcov .coverage coverage.xml

reset: ## â™»ï¸ Clean and reinstall dev environment
	$(MAKE) clean
	rm -rf .venv
	$(MAKE) dev

health: ## â¤ï¸ Run dependency, env, and LLM checks
	$(MAKE) check-deps
	$(MAKE) check-env
	$(MAKE) check-llm

check-deps: ## ðŸ”§ Verify core tooling availability
	@echo "Tooling:"; \
	command -v uv >/dev/null && echo "  uv: OK" || echo "  uv: MISSING"; \
	command -v ollama >/dev/null && echo "  ollama: present" || echo "  ollama: not installed (optional)"; \
	[ -d .venv ] && echo "  venv: OK" || echo "  venv: missing (run make dev)"; \
	$(PYTHON) --version 2>&1 | sed 's/^/  python: /'

check-env: ## ðŸ“„ Validate .env presence and basic vars
	@if [ ! -f $(ENV_FILE) ]; then echo "  .env missing (cp .env.example .env)"; exit 1; fi; \
	echo "Environment:"; \
	grep -E '^LLM_PROVIDER=' $(ENV_FILE) | sed 's/^/  /' || true; \
	grep -E '^LLM_MODEL_NAME=' $(ENV_FILE) | sed 's/^/  /' || true

check-llm: ## ðŸ¤– Quick LLM provider health check
	@if [ ! -f $(ENV_FILE) ]; then echo "Skip LLM check (no .env)"; exit 0; fi; \
	PROV=$$(grep LLM_PROVIDER $(ENV_FILE) | cut -d'=' -f2 | tr -d '"'); \
	if [ "$$PROV" = "ollama" ]; then \
		command -v ollama >/dev/null || { echo "  Ollama not installed"; exit 1; }; \
		ollama list >/dev/null 2>&1 && echo "  Ollama reachable" || echo "  Ollama not responding"; \
	else \
		echo "  Provider $$PROV configured (no local check)"; \
	fi

# ------------------------- Ollama Management -------------------------
ollama-install: ## ðŸ“¥ Install Ollama locally (macOS/Linux)
	@if command -v ollama >/dev/null; then echo "Ollama already installed"; exit 0; fi; \
	UNAME=$$(uname -s); \
	if [ "$$UNAME" = "Darwin" ]; then \
		command -v brew >/dev/null && brew install ollama || { echo "Homebrew required"; exit 1; }; \
	else \
		curl -fsSL https://ollama.com/install.sh | sh; \
	fi

ollama-start: ## â–¶ï¸ Start Ollama daemon if not running
	@pgrep -f "ollama serve" >/dev/null || (nohup ollama serve >/dev/null 2>&1 & sleep 2)
	@echo "Ollama running"

ollama-pull: ## â¬‡ï¸ Pull configured or default model
	@MODEL=$$(grep -E '^LLM_MODEL_NAME=' $(ENV_FILE) | cut -d'=' -f2 | tr -d '"'); \
	[ -n "$$MODEL" ] || MODEL=$(OLLAMA_DEFAULT_MODEL); \
	echo "Pulling $$MODEL"; \
	ollama pull "$$MODEL" || true

ollama-setup: ## ðŸ¤– Ensure Ollama installed, started & model pulled (if provider=ollama)
	@if [ -f $(ENV_FILE) ] && grep -q 'LLM_PROVIDER="ollama"' $(ENV_FILE); then \
		$(MAKE) ollama-install; \
		$(MAKE) ollama-start; \
		$(MAKE) ollama-pull; \
	else \
		echo "Provider not ollama; skipping local setup"; \
	fi

switch-to-openai: ## ðŸ” Switch .env to OpenAI (prompts for key)
	@if [ ! -f $(ENV_FILE) ]; then echo ".env missing"; exit 1; fi; \
	read -p "OpenAI API Key: " KEY; \
	sed -i.bak 's/LLM_PROVIDER=".*"/LLM_PROVIDER="openai"/' $(ENV_FILE); \
	sed -i.bak 's/LLM_MODEL_NAME=".*"/LLM_MODEL_NAME="gpt-4o-mini"/' $(ENV_FILE); \
	grep -q 'LLM_API_KEY=' $(ENV_FILE) && sed -i.bak "s/LLM_API_KEY=".*"/LLM_API_KEY="$$KEY"/" $(ENV_FILE) || echo "LLM_API_KEY=\"$$KEY\"" >> $(ENV_FILE); \
	echo "Switched to OpenAI"

switch-to-ollama: ## ðŸ” Switch .env to Ollama default model
	@if [ ! -f $(ENV_FILE) ]; then echo ".env missing"; exit 1; fi; \
	sed -i.bak 's/LLM_PROVIDER=".*"/LLM_PROVIDER="ollama"/' $(ENV_FILE); \
	sed -i.bak 's/LLM_MODEL_NAME=".*"/LLM_MODEL_NAME="$(OLLAMA_DEFAULT_MODEL)"/' $(ENV_FILE); \
	sed -i.bak 's/LLM_API_KEY=".*"/LLM_API_KEY=""/' $(ENV_FILE); \
	echo "Switched to Ollama"

logs: ## ðŸ“œ Tail application log (if exists)
	@if [ -f logs/app.log ]; then tail -50 logs/app.log; else echo "No log file yet"; fi

# ------------------------- API Validation -------------------------
api-check: ## ðŸ” Quick API health check with HTTPie
	@command -v http >/dev/null || { echo "HTTPie required: pip install httpie"; exit 1; }
	./scripts/api_check.sh

validate: ## âœ… Validate API endpoints (alias for api-check)
	$(MAKE) api-check

# Aliases
s: setup ## âš¡ Alias for setup
f: format ## âš¡ Alias for format
l: lint-fix ## âš¡ Alias for lint-fix
q: quality ## âš¡ Alias for quality
t: test ## âš¡ Alias for test
h: health ## âš¡ Alias for health
v: validate ## âš¡ Alias for validate
